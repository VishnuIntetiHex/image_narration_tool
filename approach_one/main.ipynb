{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9a437c-3b16-44fe-9a15-acc486a2b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a5cac-e634-445b-a1d5-f13f8a207ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f58a268-da14-4a2a-8f8e-e6dbb524b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(os.getcwd())\n",
    "\n",
    "PROJECT_ROOT = BASE_DIR.parent\n",
    "\n",
    "cats_img = Image.open(f\"{PROJECT_ROOT}/images/image_2.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9902d20-39c5-4467-990c-19e1882a56af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b558815-0516-499c-a5ff-7202f997d3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579bf5190df9419086d70568dc2482e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/530 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mDetrForObjectDetection LOAD REPORT\u001b[0m from: facebook/detr-resnet-50\n",
      "Key                                                            | Status     | Details\n",
      "---------------------------------------------------------------+------------+--------\n",
      "model.backbone.model.layer2.0.downsample.1.num_batches_tracked | UNEXPECTED |        \n",
      "model.backbone.model.layer1.0.downsample.1.num_batches_tracked | UNEXPECTED |        \n",
      "model.backbone.model.layer4.0.downsample.1.num_batches_tracked | UNEXPECTED |        \n",
      "model.backbone.model.layer3.0.downsample.1.num_batches_tracked | UNEXPECTED |        \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "The image processor of type `DetrImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.6827951073646545, 'label': 'car', 'box': {'xmin': 1904, 'ymin': 922, 'xmax': 2016, 'ymax': 1025}}, {'score': 0.9888834357261658, 'label': 'car', 'box': {'xmin': 346, 'ymin': 1726, 'xmax': 1081, 'ymax': 2286}}, {'score': 0.5736234188079834, 'label': 'person', 'box': {'xmin': 1843, 'ymin': 831, 'xmax': 1948, 'ymax': 942}}, {'score': 0.8973751068115234, 'label': 'car', 'box': {'xmin': 1807, 'ymin': 1124, 'xmax': 1937, 'ymax': 1291}}, {'score': 0.5430497527122498, 'label': 'person', 'box': {'xmin': 1464, 'ymin': 1192, 'xmax': 1555, 'ymax': 1277}}, {'score': 0.9305409789085388, 'label': 'bicycle', 'box': {'xmin': 2264, 'ymin': 1505, 'xmax': 2368, 'ymax': 1646}}, {'score': 0.5767276287078857, 'label': 'person', 'box': {'xmin': 270, 'ymin': 1647, 'xmax': 391, 'ymax': 1796}}, {'score': 0.6837701201438904, 'label': 'truck', 'box': {'xmin': 250, 'ymin': 1184, 'xmax': 1065, 'ymax': 1723}}, {'score': 0.5526695251464844, 'label': 'person', 'box': {'xmin': 273, 'ymin': 1051, 'xmax': 324, 'ymax': 1138}}, {'score': 0.8177577257156372, 'label': 'person', 'box': {'xmin': 2354, 'ymin': 974, 'xmax': 2415, 'ymax': 1108}}, {'score': 0.5697546601295471, 'label': 'person', 'box': {'xmin': 2194, 'ymin': 880, 'xmax': 2271, 'ymax': 976}}, {'score': 0.9986829161643982, 'label': 'car', 'box': {'xmin': 2532, 'ymin': 1787, 'xmax': 3140, 'ymax': 2459}}, {'score': 0.8654943704605103, 'label': 'car', 'box': {'xmin': 3369, 'ymin': 2201, 'xmax': 3647, 'ymax': 2533}}, {'score': 0.9664639830589294, 'label': 'car', 'box': {'xmin': 2258, 'ymin': 1088, 'xmax': 2455, 'ymax': 1269}}, {'score': 0.9624624252319336, 'label': 'person', 'box': {'xmin': 2246, 'ymin': 1407, 'xmax': 2360, 'ymax': 1611}}, {'score': 0.6399006247520447, 'label': 'person', 'box': {'xmin': 62, 'ymin': 1271, 'xmax': 135, 'ymax': 1361}}, {'score': 0.7589386701583862, 'label': 'person', 'box': {'xmin': 41, 'ymin': 1643, 'xmax': 171, 'ymax': 1757}}, {'score': 0.9933926463127136, 'label': 'car', 'box': {'xmin': 1574, 'ymin': 1387, 'xmax': 1839, 'ymax': 1750}}, {'score': 0.9920656085014343, 'label': 'car', 'box': {'xmin': 87, 'ymin': 2224, 'xmax': 863, 'ymax': 2530}}, {'score': 0.9201856255531311, 'label': 'car', 'box': {'xmin': 2519, 'ymin': 1113, 'xmax': 2716, 'ymax': 1281}}, {'score': 0.9922475814819336, 'label': 'car', 'box': {'xmin': 2978, 'ymin': 1520, 'xmax': 3645, 'ymax': 2193}}, {'score': 0.7131668925285339, 'label': 'car', 'box': {'xmin': 1722, 'ymin': 961, 'xmax': 1858, 'ymax': 1086}}, {'score': 0.9968135952949524, 'label': 'car', 'box': {'xmin': 2642, 'ymin': 1274, 'xmax': 2942, 'ymax': 1526}}, {'score': 0.8429352045059204, 'label': 'person', 'box': {'xmin': 2286, 'ymin': 943, 'xmax': 2349, 'ymax': 1071}}, {'score': 0.8383404612541199, 'label': 'person', 'box': {'xmin': 2439, 'ymin': 1014, 'xmax': 2492, 'ymax': 1148}}, {'score': 0.9304675459861755, 'label': 'person', 'box': {'xmin': 2801, 'ymin': 725, 'xmax': 2961, 'ymax': 970}}, {'score': 0.8030658960342407, 'label': 'car', 'box': {'xmin': 1995, 'ymin': 924, 'xmax': 2113, 'ymax': 1019}}, {'score': 0.9956125020980835, 'label': 'car', 'box': {'xmin': 1247, 'ymin': 1743, 'xmax': 1740, 'ymax': 2349}}, {'score': 0.9079803228378296, 'label': 'person', 'box': {'xmin': 221, 'ymin': 1246, 'xmax': 275, 'ymax': 1336}}, {'score': 0.8990422487258911, 'label': 'person', 'box': {'xmin': 2403, 'ymin': 1009, 'xmax': 2455, 'ymax': 1138}}, {'score': 0.8280318975448608, 'label': 'bicycle', 'box': {'xmin': 2260, 'ymin': 1513, 'xmax': 2362, 'ymax': 1638}}, {'score': 0.5667881965637207, 'label': 'truck', 'box': {'xmin': 1, 'ymin': 1318, 'xmax': 528, 'ymax': 1992}}, {'score': 0.8174168467521667, 'label': 'person', 'box': {'xmin': 2297, 'ymin': 925, 'xmax': 2362, 'ymax': 1039}}, {'score': 0.8010169863700867, 'label': 'car', 'box': {'xmin': 1135, 'ymin': 2434, 'xmax': 1585, 'ymax': 2534}}, {'score': 0.5320619344711304, 'label': 'car', 'box': {'xmin': 1707, 'ymin': 976, 'xmax': 1843, 'ymax': 1109}}, {'score': 0.9972900152206421, 'label': 'car', 'box': {'xmin': 1172, 'ymin': 1414, 'xmax': 1497, 'ymax': 1722}}, {'score': 0.6404605507850647, 'label': 'person', 'box': {'xmin': 280, 'ymin': 1644, 'xmax': 393, 'ymax': 1789}}, {'score': 0.9078395366668701, 'label': 'car', 'box': {'xmin': 1981, 'ymin': 1077, 'xmax': 2156, 'ymax': 1259}}, {'score': 0.9350293278694153, 'label': 'car', 'box': {'xmin': 1796, 'ymin': 1003, 'xmax': 1949, 'ymax': 1141}}, {'score': 0.9943135976791382, 'label': 'bus', 'box': {'xmin': 1312, 'ymin': 1011, 'xmax': 1716, 'ymax': 1421}}, {'score': 0.9878833889961243, 'label': 'truck', 'box': {'xmin': 1, 'ymin': 1208, 'xmax': 1067, 'ymax': 2009}}, {'score': 0.995624840259552, 'label': 'car', 'box': {'xmin': 1978, 'ymin': 1421, 'xmax': 2321, 'ymax': 1930}}, {'score': 0.8387752175331116, 'label': 'person', 'box': {'xmin': 2258, 'ymin': 1399, 'xmax': 2365, 'ymax': 1540}}, {'score': 0.9793984889984131, 'label': 'car', 'box': {'xmin': 1965, 'ymin': 2309, 'xmax': 2475, 'ymax': 2533}}, {'score': 0.9945038557052612, 'label': 'car', 'box': {'xmin': 2304, 'ymin': 1245, 'xmax': 2575, 'ymax': 1514}}, {'score': 0.5101099014282227, 'label': 'truck', 'box': {'xmin': 446, 'ymin': 1196, 'xmax': 1089, 'ymax': 1721}}, {'score': 0.7054446935653687, 'label': 'car', 'box': {'xmin': 1714, 'ymin': 943, 'xmax': 1846, 'ymax': 1059}}, {'score': 0.990053653717041, 'label': 'car', 'box': {'xmin': 1680, 'ymin': 1183, 'xmax': 1894, 'ymax': 1433}}, {'score': 0.6295565962791443, 'label': 'person', 'box': {'xmin': 1989, 'ymin': 709, 'xmax': 2077, 'ymax': 805}}, {'score': 0.982801616191864, 'label': 'car', 'box': {'xmin': 1030, 'ymin': 1131, 'xmax': 1182, 'ymax': 1322}}, {'score': 0.9432591199874878, 'label': 'car', 'box': {'xmin': 1979, 'ymin': 1251, 'xmax': 2201, 'ymax': 1469}}, {'score': 0.961723804473877, 'label': 'car', 'box': {'xmin': 1979, 'ymin': 1240, 'xmax': 2195, 'ymax': 1457}}, {'score': 0.9276826977729797, 'label': 'car', 'box': {'xmin': 2425, 'ymin': 1013, 'xmax': 2602, 'ymax': 1183}}, {'score': 0.7550756931304932, 'label': 'person', 'box': {'xmin': 2093, 'ymin': 908, 'xmax': 2177, 'ymax': 1026}}, {'score': 0.5912028551101685, 'label': 'truck', 'box': {'xmin': 1976, 'ymin': 1413, 'xmax': 2329, 'ymax': 1946}}, {'score': 0.6863909363746643, 'label': 'person', 'box': {'xmin': 2195, 'ymin': 864, 'xmax': 2278, 'ymax': 961}}, {'score': 0.9924403429031372, 'label': 'car', 'box': {'xmin': 2378, 'ymin': 1487, 'xmax': 2758, 'ymax': 1855}}, {'score': 0.7334420084953308, 'label': 'person', 'box': {'xmin': 2163, 'ymin': 881, 'xmax': 2247, 'ymax': 987}}]\n"
     ]
    }
   ],
   "source": [
    "image_segmentation = pipeline(\n",
    "    task=\"object-detection\",\n",
    "    model=\"facebook/detr-resnet-50\"\n",
    ")\n",
    "\n",
    "detections = image_segmentation(cats_img)\n",
    "\n",
    "print(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e92261-e8b9-4c14-99f7-21f959e00d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc5e27b7-4fa1-4499-b70e-067a342b8862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'car', 'person', 'car', 'person', 'bicycle', 'person', 'truck', 'person', 'person', 'person', 'car', 'car', 'car', 'person', 'person', 'person', 'car', 'car', 'car', 'car', 'car', 'car', 'person', 'person', 'person', 'car', 'car', 'person', 'person', 'bicycle', 'truck', 'person', 'car', 'car', 'car', 'person', 'car', 'car', 'bus', 'truck', 'car', 'person', 'car', 'car', 'truck', 'car', 'car', 'person', 'car', 'car', 'car', 'car', 'person', 'truck', 'person', 'car', 'person']\n"
     ]
    }
   ],
   "source": [
    "labels = [x['label'] for x in detections]\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144a0fb-c403-4190-a3d5-ef0f2500aa1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3813fb86-fd9b-4205-854e-953102b49ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = {}\n",
    "\n",
    "for label in labels:\n",
    "    if objects.get(label):\n",
    "        objects[label] += 1\n",
    "    else:\n",
    "        objects[label] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c785634-116b-4bda-a963-b4e9b008d9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d846e420-9a33-4ee4-bff0-b4a41f07ae1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I see 29 cars 21 persons 2 bicycles 5 trucks \n"
     ]
    }
   ],
   "source": [
    "sentence = \"I see \"\n",
    "\n",
    "for object in objects.keys():\n",
    "    sentence += f\"{objects[object]} {object}\" + 's ' if objects[object] >1 else ''\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3163941-ce0f-4d70-9d54-27104ded2679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "624d56a7-189b-4ed6-a531-208ba26c3ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38cdb1312485451b85350de0c10fba52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tied weights mapping and config for this model specifies to tie fine_acoustics.input_embeds_layers.1.weight to fine_acoustics.lm_heads.0.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "The tied weights mapping and config for this model specifies to tie fine_acoustics.input_embeds_layers.2.weight to fine_acoustics.lm_heads.1.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "The tied weights mapping and config for this model specifies to tie fine_acoustics.input_embeds_layers.3.weight to fine_acoustics.lm_heads.2.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "The tied weights mapping and config for this model specifies to tie fine_acoustics.input_embeds_layers.4.weight to fine_acoustics.lm_heads.3.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "The tied weights mapping and config for this model specifies to tie fine_acoustics.input_embeds_layers.5.weight to fine_acoustics.lm_heads.4.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "The tied weights mapping and config for this model specifies to tie fine_acoustics.input_embeds_layers.6.weight to fine_acoustics.lm_heads.5.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "The tied weights mapping and config for this model specifies to tie fine_acoustics.input_embeds_layers.7.weight to fine_acoustics.lm_heads.6.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n",
      "Passing `generation_config` together with generation-related arguments=({'return_dict_in_generate', 'min_eos_p'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Both `max_new_tokens` (=768) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Passing `generation_config` together with generation-related arguments=({'return_dict_in_generate', 'max_new_tokens'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=60) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=56) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "speech_audio = pipeline(\n",
    "    task=\"text-to-audio\",\n",
    "    model=\"suno/bark-small\"\n",
    ")\n",
    "\n",
    "gen_audio = speech_audio(sentence)\n",
    "\n",
    "scipy.io.wavfile.write(\"traffic_sentence.wav\", rate=gen_audio[\"sampling_rate\"], data=gen_audio[\"audio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3f0ca0-3e82-4d0a-8e25-e9fe7523cc67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
